name: ingestao-continuada

on:
  workflow_dispatch:
  schedule:
    - cron: "*/15 * * * *"   # a cada 15 min

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 50

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install requests python-slugify

      - name: Ingestão com imagem
        env:
          WC_BASE: ${{ secrets.WC_BASE }}   # ex.: https://ctctech.store
          WC_CK:   ${{ secrets.WC_CK }}
          WC_CS:   ${{ secrets.WC_CS }}
        run: |
          python - <<'PY'
          import os, re, time, json, random, html, hashlib, urllib.parse, requests
          from slugify import slugify

          BASE = os.environ["WC_BASE"].rstrip("/")
          CK   = os.environ["WC_CK"]
          CS   = os.environ["WC_CS"]

          S = requests.Session()
          S.headers.update({
            "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122 Safari/537.36",
            "Accept-Language": "pt-BR,pt;q=0.9,en;q=0.8",
          })

          ENGINES = [
            "https://www.bing.com/search?q=",
            "https://duckduckgo.com/html/?q=",
          ]
          DOMAIN_OK = re.compile(r"(amazon\.com\.br|mercadolivre\.com\.br|shopee\.com\.br|shein\.com)", re.I)
          BAD_PATH = ("login","cart","checkout","track","seller","support","help","mailto:",
                      "account","orders","wishlist")

          def search_links(q: str):
            out=[]
            q_full = f'{q} site:amazon.com.br OR site:mercadolivre.com.br OR site:shopee.com.br OR site:shein.com'
            for eng in ENGINES:
              url = eng + urllib.parse.quote(q_full)
              try:
                r = S.get(url, timeout=20)
                r.raise_for_status()
              except Exception:
                continue
              for u in re.findall(r'https?://[^"\'\s<>]+', r.text):
                u = u.split("&")[0]
                if not u.startswith("http"): 
                  continue
                if any(x in u for x in BAD_PATH): 
                  continue
                if DOMAIN_OK.search(u):
                  out.append(u)
            seen,res=set(),[]
            for u in out:
              if u not in seen:
                seen.add(u); res.append(u)
            return res[:60]

          def extract_meta(url: str):
            try:
              r = S.get(url, timeout=25)
              r.raise_for_status()
            except Exception:
              return None
            t = r.text
            def m(prop):
              z = re.search(rf'<meta[^>]+property=["\']{prop}["\'][^>]+content=["\']([^"\']+)["\']', t, re.I)
              if not z:
                z = re.search(rf'<meta[^>]+name=["\']{prop}["\'][^>]+content=["\']([^"\']+)["\']', t, re.I)
              return html.unescape(z.group(1).strip()) if z else ""
            title = m("og:title") or m("twitter:title")
            if not title:
              zz = re.search(r"<title>(.*?)</title>", t, re.I|re.S)
              title = zz.group(1).strip() if zz else ""
            img   = m("og:image") or m("twitter:image")
            price = ""
            z = re.search(r'content=["\']R?\$?\s?(\d{1,3}(?:[\.\s]\d{3})*(?:,\d{2})?)["\'][^>]+property=["\']product:price:amount["\']', t, re.I)
            if not z:
              z = re.search(r'R\$\s?(\d{1,3}(?:[\.\s]\d{3})*(?:,\d{2})?)', t)
            if z:
              price = z.group(1).replace(".", "").replace(" ", "").replace(",", ".")
            if not title:
              return None
            return {"title": title[:180], "image": img, "price": price}

          def wc_get_by_sku(sku: str):
            try:
              r = S.get(
                f"{BASE}/wp-json/wc/v3/products",
                params={"sku": sku, "per_page":1, "consumer_key":CK, "consumer_secret":CS},
                timeout=20
              )
              r.raise_for_status()
              arr = r.json()
              if arr:
                pid = arr[0]["id"]
                has_img = bool(arr[0].get("images"))
                return pid, has_img
            except Exception:
              pass
            return None, False

          def wc_create(meta, url, sku):
            data = {
              "name": meta["title"],
              "type": "simple",
              "status": "publish",
              "regular_price": meta["price"] or "0",
              "sku": sku,
              "external_url": url,
              "catalog_visibility": "visible",
              "short_description": f"Importado automaticamente. Fonte: {url}",
              "images": ([{"src": meta["image"]}] if meta["image"] else []),
              "categories": [],
              "tags": [],
            }
            try:
              r = S.post(
                f"{BASE}/wp-json/wc/v3/products",
                params={"consumer_key":CK, "consumer_secret":CS},
                json=data, timeout=25
              )
              r.raise_for_status()
              return True
            except Exception:
              return False

          def wc_update_image(pid:int, img:str):
            try:
              r = S.put(
                f"{BASE}/wp-json/wc/v3/products/{pid}",
                params={"consumer_key":CK, "consumer_secret":CS},
                json={"images":[{"src": img}]}, timeout=25
              )
              r.raise_for_status()
              return True
            except Exception:
              return False

          QUERIES = [
            "smartphone 128gb preço",
            "smartwatch masculino promoção",
            "headset gamer bluetooth",
            "caixa de som portátil",
            "fone bluetooth tws",
            "notebook i5 8gb ssd",
            "mouse gamer rgb",
            "tv stick 4k",
          ]

          random.shuffle(QUERIES)
          created = 0
          updated = 0
          skipped = 0
          max_per_run = 12

          for q in QUERIES:
            if created + updated >= max_per_run:
              break
            for u in search_links(q):
              if created + updated >= max_per_run:
                break
              meta = extract_meta(u)
              if not meta:
                continue

              sku = hashlib.md5(u.encode("utf-8")).hexdigest()[:12].upper()
              pid, has_img = wc_get_by_sku(sku)

              if pid:
                if (not has_img) and meta["image"]:
                  if wc_update_image(pid, meta["image"]):
                    updated += 1
                else:
                  skipped += 1
                continue

              if wc_create(meta, u, sku):
                created += 1

              time.sleep(random.uniform(0.6, 1.6))

          print(json.dumps({"created": created, "updated": updated, "skipped": skipped}, ensure_ascii=False))
          PY
