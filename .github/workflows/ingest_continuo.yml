name: ingestao-continuada

on:
  workflow_dispatch:
  schedule:
    - cron: "*/10 * * * *"  # a cada 10 min

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Instalar deps
        run: |
          python -m pip install --upgrade pip
          pip install requests python-slugify

      - name: Ingestão global com imagem
        env:
          WC_BASE: ${{ secrets.WC_BASE }}
          WC_CK:   ${{ secrets.WC_CK }}
          WC_CS:   ${{ secrets.WC_CS }}
        run: |
          python - <<'PY'
          import os, re, time, json, random, html, hashlib, urllib.parse, requests
          from slugify import slugify

          BASE = os.environ["WC_BASE"].rstrip("/")
          CK   = os.environ["WC_CK"]
          CS   = os.environ["WC_CS"]

          S = requests.Session()
          S.headers.update({
            "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122 Safari/537.36",
            "Accept-Language": "pt-BR,pt;q=0.9,en;q=0.8",
          })

          ENGINES = [
            "https://www.bing.com/search?q=",
            "https://duckduckgo.com/html/?q=",
          ]

          DOMAINS = [
            # BR
            "amazon.com.br","mercadolivre.com.br","shopee.com.br","magazineluiza.com.br","americanas.com.br",
            "submarino.com.br","kabum.com.br","casasbahia.com.br","pontofrio.com.br","extra.com.br",
            "dell.com","lenovo.com","acer.com","samsung.com","apple.com","aliexpress.com",
            # Global marketplaces
            "amazon.com","ebay.com","bestbuy.com","aliexpress.us","newegg.com","walmart.com",
            # Veículos 0km (fabricantes)
            "toyota.com","volkswagen.com","ford.com","chevrolet.com","honda.com","bmw.com","mercedes-benz.com",
            "audi.com","tesla.com","renault.com","peugeot.com","fiat.com","hyundai.com","kia.com",
            # Joias e luxo
            "cartier.com","bvlgari.com","tiffany.com","rolex.com","omega.com","tagheuer.com","vancleefarpels.com"
          ]

          BAD_PATH = (
            "login","cart","checkout","track","seller","support","help","mailto:",
            "account","orders","wishlist","entrar","minha-conta","signin","signup"
          )

          PRICE_RX = re.compile(
            r"(?:R\$\s*|US\$\s*|€\s*|£\s*)?(\d{1,3}(?:[.\s]\d{3})*(?:,\d{2})?|\d+(?:\.\d{2})?)",
            re.I
          )

          def search_links(q: str):
            q_domains = " OR ".join([f"site:{d}" for d in DOMAINS])
            query = f"{q} {q_domains}"
            out = []
            for eng in ENGINES:
              url = eng + urllib.parse.quote(query)
              try:
                r = S.get(url, timeout=25)
                r.raise_for_status()
              except Exception:
                continue
              for u in re.findall(r'https?://[^"\']+', r.text):
                u = u.split("&")[0]
                if not u.startswith("http"): 
                  continue
                if any(x in u for x in BAD_PATH): 
                  continue
                out.append(u)
            # dedup preservando ordem
            seen, res = set(), []
            for u in out:
              if u not in seen:
                seen.add(u); res.append(u)
            return res[:120]

          def extract_meta(url: str):
            try:
              r = S.get(url, timeout=30)
              r.raise_for_status()
            except Exception:
              return None
            t = r.text

            def meta(prop):
              m = re.search(rf'<meta[^>]+property=["\']{prop}["\'][^>]+content=["\']([^"\']+)["\']', t, re.I)
              if not m:
                m = re.search(rf'<meta[^>]+name=["\']{prop}["\'][^>]+content=["\']([^"\']+)["\']', t, re.I)
              return html.unescape(m.group(1).strip()) if m else ""

            title = meta("og:title") or meta("twitter:title")
            if not title:
              m = re.search(r"<title>(.*?)</title>", t, re.I|re.S)
              title = html.unescape(m.group(1)).strip() if m else ""

            # tenta várias chaves de imagem
            img = (meta("og:image") or meta("twitter:image") or
                   (re.search(r'<img[^>]+src=["\']([^"\']+\.(?:jpg|jpeg|png|webp))["\']', t, re.I) or (None,))[1] if re.search(r'<img', t, re.I) else "")

            price = ""
            mprice = re.search(r'product:price:amount["\'][^>]*content=["\']([^"\']+)["\']', t, re.I)
            if not mprice:
              mprice = PRICE_RX.search(t)
            if mprice:
              p = mprice.group(1)
              if "," in p and p.count(",")==1 and "." in p:
                # já no formato 1,234.56 -> deixa
                price = p
              elif "," in p and not "." in p:
                price = p.replace(".", "").replace(" ", "").replace(",", ".")
              else:
                price = p

            if not title:
              return None
            return {"title": title[:180], "image": img, "price": price}

          def get_by_sku(sku: str):
            url = f"{BASE}/wp-json/wc/v3/products"
            try:
              r = S.get(url, params={"sku": sku, "per_page":1,
                                     "consumer_key":CK, "consumer_secret":CS}, timeout=25)
              r.raise_for_status()
              arr = r.json()
              if arr:
                pid = arr[0]["id"]
                imgs = arr[0].get("images") or []
                return pid, (len(imgs)>0)
            except Exception:
              pass
            return None, False

          def create_or_update_product(meta, url):
            title = meta["title"]
            img   = meta["image"]
            price = meta["price"] or "0"
            sku   = hashlib.md5(url.encode("utf-8")).hexdigest()[:16].upper()

            pid, has_img = get_by_sku(sku)
            api = f"{BASE}/wp-json/wc/v3/products"

            if pid and (not has_img) and img:
              try:
                r = S.put(f"{api}/{pid}",
                          params={"consumer_key":CK, "consumer_secret":CS},
                          json={"images":[{"src": img}]}, timeout=25)
                r.raise_for_status()
                return "updated"
              except Exception:
                return "error"

            if pid:
              return "skip"

            data = {
              "name": title,
              "type": "simple",
              "status": "publish",
              "regular_price": str(price),
              "sku": sku,
              "external_url": url,
              "catalog_visibility": "visible",
              "short_description": f"Importado automaticamente. Fonte: {url}",
              "images": ([{"src": img}] if img else []),
              "categories": [],
              "tags": [],
            }
            try:
              r = S.post(api,
                         params={"consumer_key":CK, "consumer_secret":CS},
                         json=data, timeout=25)
              r.raise_for_status()
              return "created"
            except Exception:
              return "error"

          QUERIES = [
            # eletrônicos
            "smartphone 256gb 5g preço", "iphone 15 pro oferta", "s22 ultra preço",
            "notebook i7 16gb ssd 1tb", "ssd nvme 1tb", "placa de vídeo rtx 4070",
            "tv 55 4k", "roteador wi-fi 6 ax3000", "headset gamer bluetooth",
            "caixa de som portátil", "smartwatch masculino promoção",
            # veículos 0km
            "carro 0km preço site fabricante", "moto 0km lançamento site fabricante",
            # joias
            "anel ouro 18k original", "relógio automático suíço original"
          ]

          random.shuffle(QUERIES)
          created = 0
          updated = 0
          skipped = 0
          max_per_run = 25

          for q in QUERIES:
            if created + updated >= max_per_run:
              break
            for u in search_links(q):
              if created + updated >= max_per_run:
                break
              meta = extract_meta(u)
              if not meta:
                continue
              result = create_or_update_product(meta, u)
              if result == "created":
                created += 1
              elif result == "updated":
                updated += 1
              elif result == "skip":
                skipped += 1
              time.sleep(random.uniform(0.4, 1.2))

          print(json.dumps({"created": created, "updated": updated, "skipped": skipped}, ensure_ascii=False))
          PY
